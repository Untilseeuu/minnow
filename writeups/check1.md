Checkpoint 1 实验报告
====================

姓名：孟许程

学号：[非斯坦福学生 - 外部实现]

协作者：无（独立完成）

本实验耗时：12 小时

说明：作为非斯坦福学生，我无法完成需要访问CS144私有网络的实践部分（Section 2）。
我已完成核心的Reassembler实现（Section 3）。

---

## 1. 结构与设计

### 数据结构选择

Reassembler使用以下私有成员变量：

- `std::map<uint64_t, std::string> unassembled_`：存储乱序到达的子串，
  以起始索引作为键。使用map可以自动按索引排序，方便快速检查下一个期待的
  字节是否已到达。

- `uint64_t next_index_`：记录下一个期待写入ByteStream的字节索引。
  所有小于此索引的字节都已写入完成。

- `uint64_t unassembled_bytes_`：维护`unassembled_`中存储的总字节数。
  这个变量对于在不遍历整个map的情况下检查容量约束非常关键。

- `bool eof_received_`：标记是否已接收到最后一个子串。

- `uint64_t eof_index_`：记录流结束的位置（仅在`eof_received_`为true时有效）。

### 设计思路

整个实现采用三阶段处理流程：

1. **边界检查**：丢弃已写入的数据或超出容量限制的数据。

2. **重叠处理**：首先检查新数据是否完全被已有片段覆盖。如果没有，则遍历
   所有已存在的片段，删除或修剪重叠部分，确保不存储冗余数据。

3. **推送数据**：插入新片段后，立即将从`next_index_`开始的所有连续数据
   推送到ByteStream。

### 关键不变式

- `unassembled_bytes_`始终等于`unassembled_`中所有字符串长度之和
- `unassembled_`中任何时刻都不存在重叠的片段
- 总内存占用（ByteStream已缓冲 + 未组装）始终不超过capacity
- 只要前面所有字节都已到达，数据就会立即写入ByteStream

---

## 2. 设计方案对比

### 方案A：std::map（最终采用）

**优点：**
- 自动按索引排序，查找下一个连续片段的时间复杂度为O(1)
- 支持高效的范围查询，方便重叠检测
- API简洁清晰，易于使用

**缺点：**
- 红黑树结构带来一定的内存开销
- 每个片段单独存储，没有合并相邻片段

**性能表现：** 通过了速度测试，远超0.1 Gbit/s的最低要求。

### 方案B：std::deque + 区间管理

**优点：**
- 相比树结构内存开销更小
- 理论上更容易合并相邻片段

**缺点：**
- 每次插入后需要手动排序
- 重叠检测需要线性扫描，效率较低
- 实现复杂度大约是当前方案的2-3倍

**未采用原因：** O(n)的插入复杂度以及较高的实现难度，内存上的优势并不足以
弥补这些缺点。

### 方案C：固定大小循环缓冲区

**优点：**
- 内存占用固定，便于控制
- 连续内存布局对cache友好

**缺点：**
- 环形逻辑比较复杂，容易出错
- 难以处理稀疏到达的情况（片段间有大间隙）
- 还需要额外的数据结构来跟踪"空洞"位置

**未采用原因：** TCP片段可能以很大的间隙到达，简单的循环缓冲区无法很好地
处理这种情况。

### 方案D：区间树（增强型二叉搜索树）

**优点：**
- 理论上最优的O(log n)重叠查询
- 面对大量重叠片段时效率很高

**缺点：**
- 实现难度大，代码量预计在200行以上
- 对于典型的TCP场景（重叠相对较少）来说过于复杂
- 后期维护和调试都比较困难

**未采用原因：** 实现复杂度远超性能需求，简单直接的map方案就已经足够。

### 性能对比分析

虽然没有进行正式的性能测试，但基于理论分析：
- Map方案：每次插入O(k log n)，k为重叠片段数
- Deque方案：每次插入O(n)，因为需要排序
- 区间树方案：每次插入O(log n)，但常数因子较大

对于重叠较少的典型TCP场景，map在简洁性和性能之间达到了最佳平衡。

---

## 3. 实现过程中遇到的问题

### 问题1：正确处理各种重叠情况

最大的难点是确保重叠处理逻辑能够正确应对所有可能的场景：

- 新片段完全被已有片段覆盖
- 新片段完全覆盖已有片段
- 新片段开头部分与已有片段重叠
- 新片段结尾部分与已有片段重叠
- 新片段将已有片段分成前后两部分

**解决过程：** 最开始我试图用复杂的条件判断在插入时直接处理所有重叠情况，
结果导致了各种bug。后来想明白了，应该把逻辑分成两个阶段：

1. 先检查新数据是否完全冗余，如果是就直接返回
2. 然后遍历现有片段，针对每种重叠情况分别处理

**调试经历：** `reassembler_overlapping`测试最初在"bcd"@索引1之后插入"c"@
索引2时失败了。我加了一些调试输出跟踪`unassembled_bytes_`的变化，发现是
"新片段完全被覆盖"这种情况没处理好。加上提前返回的检查后就修复了。

### 问题2：维护unassembled_bytes_计数的准确性

刚开始实现时，有些代码分支忘记更新`unassembled_bytes_`，导致测试失败，
显示的待处理字节数跟实际情况对不上。

**解决方法：** 制定了一个严格的编码规则：每次修改`unassembled_`（无论是
插入、删除还是修改），都要在同一个代码块里立即更新`unassembled_bytes_`。
用+=和-=运算符来记录变化量，这样比较不容易出错。

**检查方式：** 写代码时经常问自己："现在unassembled_bytes_的值还等于所有
片段长度的总和吗？"这种防御性的思维方式帮我发现了好几个潜在的bug。

### 问题3：理解容量的准确含义

一开始不太清楚ByteStream的容量和Reassembler的存储限制之间是什么关系。
容量是包括已缓冲和未组装的字节总和，还是只算未组装的部分？

**理解过程：** 反复阅读实验说明并仔细研究了第6页的图示，终于明白了
`first_unacceptable = next_index_ + available_capacity()`这个边界的含义。
其中available_capacity已经减去了ByteStream中已缓冲的字节，所以Reassembler
只能在这个"窗口"范围内存储数据。

**验证方法：** 实现之前先手动模拟了一遍`reassembler_cap`测试用例的执行过程，
确保自己真正理解了。

### 问题4：EOF边界情况的处理

什么时候该关闭ByteStream需要仔细考虑：
- 必须同时满足`eof_received_`为true且`next_index_ >= eof_index_`
- 每次推送数据后都要检查这个条件
- 还要处理空数据但`is_last_substring = true`的情况

**解决办法：** 在多个关键位置（边界检查后、推送数据后）都加上了EOF关闭
检查，确保只要条件满足就能立即关闭流。

---

## 4. 已知问题

**目前没有发现bug。** 所有18个checkpoint测试都通过了，包括：
- 基础功能测试（single、seq、cap）
- 边界情况测试（holes、dup、overlapping）
- 压力测试（reassembler_win）
- 性能测试（speed_test）

**可能存在但未测试到的边界情况：**
- 接近uint64_t最大值的极大容量
- 病态的重叠模式（比如上千个重叠片段同时存在）

不过考虑到测试用例的覆盖面以及设计本身的简洁性，我相信这个实现对于所有
正常的使用场景都是可靠的。

---

## 代码统计

- 新增代码：约117行（包括注释）
- 总耗时：12小时
  - 设计和规划：2小时
  - 初始实现：4小时
  - 调试和测试：5小时
  - 代码整理和文档：1小时
